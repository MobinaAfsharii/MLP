{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor:\n",
    "\n",
    "  def __init__(self, value, label='', children=(), operator=None):\n",
    "    self.value = value\n",
    "    self.children = set(children)\n",
    "    self.operator = operator\n",
    "    self.grad = 0\n",
    "    self._backward = lambda  : None\n",
    "    self.label = label\n",
    "\n",
    "  def __repr__(self) -> str:\n",
    "    return f\"Tensor(value={self.value})\"\n",
    "\n",
    "  def __mul__(self, other):\n",
    "    other = other if isinstance(other, Tensor) else Tensor(other)\n",
    "    \n",
    "    out = Tensor(self.value*other.value, children= (self, other), operator='*')\n",
    "    \n",
    "    def backward():\n",
    "      self.grad += other.value * out.grad\n",
    "      other.grad += self.value * out.grad\n",
    "    \n",
    "    out._backward = backward\n",
    "    \n",
    "    return out\n",
    "\n",
    "  def __add__(self, other):\n",
    "    other = other if isinstance(other, Tensor) else Tensor(other)\n",
    "    \n",
    "    out = Tensor(self.value+other.value, children= (self, other), operator='+')\n",
    "    \n",
    "    def backward():\n",
    "      self.grad += 1 * out.grad\n",
    "      other.grad += 1 * out.grad\n",
    "    \n",
    "    out._backward = backward\n",
    "    \n",
    "    return out\n",
    "  def __pow__(self, other):\n",
    "\n",
    "    input_value = self.value\n",
    "    output_value = pow(input_value, other)\n",
    "\n",
    "    out = Tensor(output_value, children=(self,), operator='pow')\n",
    "\n",
    "    def backward():\n",
    "      self.grad = other * pow(self.value, other-1) * out.grad\n",
    "\n",
    "    out._backward = backward\n",
    "\n",
    "    return out\n",
    "  \n",
    "  def __sub__(self, other):\n",
    "    return self + (-other)\n",
    "  \n",
    "  def __truediv__(self, other):\n",
    "    other = other if isinstance(other, Tensor) else Tensor(other)\n",
    "    if other.value == 0:\n",
    "        raise ValueError(\"Division by zero\")\n",
    "    out = Tensor(self.value / other.value, children=(self, other), operator='/')\n",
    "\n",
    "    def backward():\n",
    "        self.grad += (1 / other.value) * out.grad\n",
    "        other.grad += (-self.value / (other.value ** 2)) * out.grad\n",
    "\n",
    "    out._backward = backward\n",
    "    return out\n",
    "\n",
    "  def backward(self):\n",
    "\n",
    "    topo_sort = []\n",
    "    visited = set()\n",
    "\n",
    "    def build_topo(v):\n",
    "      if v not in visited:\n",
    "        visited.add(v)\n",
    "        for child in v.children:\n",
    "          build_topo(child)\n",
    "        topo_sort.append(v)\n",
    "    \n",
    "    build_topo(self)\n",
    "\n",
    "    self.grad = 1\n",
    "    for v in reversed(topo_sort):\n",
    "      v._backward()\n",
    "\n",
    "\n",
    "  def __radd__(self, other):\n",
    "    return self + other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "\n",
    "  def __init__(self, input_size):\n",
    "    self.weights = [Tensor(1) for i in range(input_size)]\n",
    "    self.bias = Tensor(1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    res = sum([w_i * x_i for w_i, x_i in zip(self.weights, x)]) + self.bias\n",
    "    res.value = 1 / (1 + math.exp(res.value))\n",
    "    return res\n",
    "\n",
    "  def __call__(self, x):\n",
    "    return self.forward(x)\n",
    "\n",
    "  def parameters(self) -> list[Tensor]:\n",
    "    return self.weights + [self.bias]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "\n",
    "  def __init__(self, input_size, output_size):\n",
    "    self.neurons = [Neuron(input_size) for _ in range(output_size)]\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = [neuron(x) for neuron in self.neurons]\n",
    "    return out[0] if len(out)==1 else out\n",
    "\n",
    "  def __call__(self, x):\n",
    "    return self.forward(x)\n",
    "  \n",
    "  def parameters(self) -> list[Tensor]:\n",
    "    return[param for neuron in self.neurons for param in neuron.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "\n",
    "  def __init__(self, input_size, layer_sizes):\n",
    "    layers_total = [input_size] + layer_sizes\n",
    "    self.layers = [Layer(layers_total[i], layers_total[i+1]) for i in range(len(layer_sizes))]\n",
    "\n",
    "  def forward(self, x):\n",
    "    for layer in self.layers:\n",
    "      x = layer(x)\n",
    "    return x\n",
    "\n",
    "  def __call__(self, x):\n",
    "    return self.forward(x)\n",
    "\n",
    "  def parameters(self) -> list[Tensor]:\n",
    "    return[param for layer in self.layers for param in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 3\n",
    "layer_sizes = [2, 3, 1]\n",
    "model = MLP(input_size, layer_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(y_hat: list[Tensor], Y:list[int]) -> Tensor:\n",
    "\n",
    "  return sum([ (y_hat-Y)**2 for y_hat, Y in zip(y_hat, Y)])/len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[2.0, 3.0, -1.0],\n",
    "    [3.0, -1.0, 0.5], \n",
    "    [0.5, 1.0, 1.0], \n",
    "    [1.0, 1.0, -1.0]]\n",
    "    \n",
    "Y = [1.0, -1.0, -1.0, 1.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "  def __init__(self, parameters: list[Tensor], lr: float):\n",
    "    self.parameters = parameters\n",
    "    self.lr = lr\n",
    "\n",
    "  def zero_grad(self):\n",
    "    for parameter in self.parameters:\n",
    "      parameter.grad = 0\n",
    "\n",
    "  def step(self):\n",
    "    for parameter in self.parameters:\n",
    "      parameter.value += self.lr * parameter.grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = Optimizer(model.parameters(), 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: Tensor(value=1.017091683001651)\n",
      "epoch: 2, loss: Tensor(value=1.0161398719826054)\n",
      "epoch: 3, loss: Tensor(value=1.0152021909648021)\n",
      "epoch: 4, loss: Tensor(value=1.0142710818241834)\n",
      "epoch: 5, loss: Tensor(value=1.0133395674449681)\n",
      "epoch: 6, loss: Tensor(value=1.0124011773632082)\n",
      "epoch: 7, loss: Tensor(value=1.0114498727156216)\n",
      "epoch: 8, loss: Tensor(value=1.0104799729402296)\n",
      "epoch: 9, loss: Tensor(value=1.009486086326592)\n",
      "epoch: 10, loss: Tensor(value=1.008463046518633)\n",
      "epoch: 11, loss: Tensor(value=1.0074058574026938)\n",
      "epoch: 12, loss: Tensor(value=1.0063096494381938)\n",
      "epoch: 13, loss: Tensor(value=1.005169651367922)\n",
      "epoch: 14, loss: Tensor(value=1.0039811823125226)\n",
      "epoch: 15, loss: Tensor(value=1.0027396703947955)\n",
      "epoch: 16, loss: Tensor(value=1.0014407050673357)\n",
      "epoch: 17, loss: Tensor(value=1.0000801309471685)\n",
      "epoch: 18, loss: Tensor(value=0.9986541907915023)\n",
      "epoch: 19, loss: Tensor(value=0.9971597237608154)\n",
      "epoch: 20, loss: Tensor(value=0.9955944217155644)\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "for i in range(n_epochs):\n",
    "  y_hats = [model(x) for x in X]\n",
    "  loss = criterion(y_hats, Y)\n",
    "\n",
    "  optim.zero_grad()\n",
    "  \n",
    "  loss.backward()\n",
    "  \n",
    "  optim.step()\n",
    "  print(f'epoch: {i + 1}, loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
